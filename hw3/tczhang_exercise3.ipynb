{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDataExercise3(filepath):\n",
    "    data = []\n",
    "    with open(filepath) as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip().split(',')\n",
    "            data.append(line[-2:])        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'ex3_data.csv'\n",
    "data = ReadDataExercise3(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncodePeptide(sequence):\n",
    "    num_aa = len(sequence)\n",
    "    AminoAcids = [\n",
    "        \"G\", \"A\", \"S\", \"P\", \"V\",\n",
    "        \"T\", \"C\", \"I\", \"L\", \"N\",\n",
    "        \"D\", \"K\", \"Q\", \"E\", \"M\",\n",
    "        \"H\", \"F\", \"R\", \"Y\", \"W\"\n",
    "    ]\n",
    "    AminoAcids = sorted(AminoAcids)\n",
    "    AA_Dictionary = {key:i for i,key in enumerate(AminoAcids)}\n",
    "    \n",
    "    one_hot_seq = np.zeros((num_aa,len(AminoAcids)))\n",
    "    for i, letter in enumerate(sequence):\n",
    "        one_hot_seq[i,AA_Dictionary[letter]] = 1\n",
    "    return one_hot_seq.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_data = [OneHotEncodePeptide(str(x[0])) for x in data]\n",
    "processed_data = [[x, *y] for x,y in zip(oh_data, data)] # one-hot encoded, aa_sequence, label\n",
    "x = np.array([ele[0] for ele in processed_data])\n",
    "x_seq = [ele[1] for ele in processed_data]\n",
    "y = np.array([float(ele[2]) for ele in processed_data])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use the GP in the same way multiple times, so let's create a function\n",
    "def GP_analysis(X, Y, X_grid):\n",
    "    # Use GP regression to fit the data\n",
    "    k = GPy.kern.RBF(X.shape[1])\n",
    "    m = GPy.models.SparseGPRegression(X, Y, k)\n",
    "    m.optimize('bfgs', max_iters=10)\n",
    "\n",
    "    # Predict the mean and covariance of the GP fit over the grid\n",
    "    mean, Cov = m.predict(X_grid, full_cov=True)\n",
    "    variance = np.diag(Cov)\n",
    "    return mean, Cov, variance, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianProcess(x, y, split_percent, seed):\n",
    "    \"\"\" Chooses next sample using gaussian process \"\"\"\n",
    "    # Split data into test and train.\n",
    "    rng = np.random.default_rng(seed)\n",
    "    shuffled_idx = rng.shuffle(np.arange(x.shape[0]))\n",
    "    shuffled_x = x[shuffled_idx]\n",
    "    shuffled_y = y[shuffled_idx]\n",
    "\n",
    "    n = len(y)\n",
    "    x_lab = shuffled_x[:int(n*split_percent)]\n",
    "    y_lab = shuffled_y[:int(n*split_percent)]\n",
    "    x_unlab = shuffled_x[int(n*split_percent):]\n",
    "    y_unlab = shuffled_y[int(n*split_percent):]\n",
    "\n",
    "    Dsize = len(x)\n",
    "    BO_lambda = .1\n",
    "    BO_number_of_iterations = 1\n",
    "\n",
    "    # Random sample locations\n",
    "    # X_samples = np.random.uniform(-np.pi, np.pi * 3/4, (num_measurements, 1))\n",
    "\n",
    "    # # Get the function value\n",
    "    # Y_samples = f(X_samples)\n",
    "\n",
    "    count = 0\n",
    "    percentages = []\n",
    "    samples = []\n",
    "    for i in range(0, 200):\n",
    "\n",
    "        # Use GP regression to fit the data\n",
    "        mean, Cov, variance, m = GP_analysis(x_lab, y_lab, x_unlab)\n",
    "\n",
    "        # Compute UCB\n",
    "        BO_beta = 2 * math.log(Dsize * math.pow(BO_number_of_iterations,2) * math.pow(np.pi,2) / (6 * BO_lambda) )\n",
    "        alpha_full = mean + math.sqrt(BO_beta) * variance[:,None]\n",
    "\n",
    "        # Find the next sample\n",
    "        next_sample_index = np.argmax(alpha_full)\n",
    "\n",
    "        # Logging metrics.\n",
    "        if y_unlab[next_sample_index] == 9.0:\n",
    "            count += 1\n",
    "            samples.append(x_unlab[next_sample_index])\n",
    "        percentages.append(count/(i + 1)*100)\n",
    "\n",
    "        # Remove chosen sample from unlabled and add to labled\n",
    "        x_lab = np.vstack((x_lab, x_unlab[next_sample_index]))\n",
    "        y_lab = np.append((y_lab, y_unlab[next_sample_index]))\n",
    "\n",
    "        x_unlab = np.delete(x_unlab, next_sample_index, axis = 0)\n",
    "        y_unlab = np.delete(y_unlab, next_sample_index)\n",
    "\n",
    "    return count, percentages, samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsize = len(x)\n",
    "num_measurements = x.shape[0]\n",
    "BO_lambda = .1\n",
    "BO_number_of_iterations = 1\n",
    "\n",
    "# Random sample locations\n",
    "X_samples = np.random.uniform(-np.pi, np.pi * 3/4, (num_measurements, 1))\n",
    "\n",
    "# Get the function value\n",
    "Y_samples = f(X_samples)\n",
    "\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # Use GP regression to fit the data\n",
    "    mean, Cov, variance, m = GP_analysis(X_samples, Y_samples, x)\n",
    "\n",
    "    # Compute UCB\n",
    "    BO_beta = 2 * math.log(Dsize * math.pow(BO_number_of_iterations,2) * math.pow(np.pi,2) / (6 * BO_lambda) )\n",
    "    alpha_full = mean + math.sqrt(BO_beta) * variance[:,None]\n",
    "\n",
    "    # Find the next sample\n",
    "    next_sample_index = np.argmax(alpha_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
